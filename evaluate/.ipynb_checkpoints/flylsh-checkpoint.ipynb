{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time\n",
    "import numpy as np\n",
    "import seaborn as sns;\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "from os import getcwd, path\n",
    "\n",
    "\n",
    "random.seed(10301949)\n",
    "np.random.seed(10301949)\n",
    "\n",
    "# basic LSH mode\n",
    "# HASH_LENGTH = 16\n",
    "# NUM_KENYON = 16\n",
    "# WTA = \"all\"\n",
    "# SPARSE = False\n",
    "# SAMPLES = 0\n",
    "\n",
    "# fly mode\n",
    "HASH_LENGTH = 16\n",
    "NUM_KENYON = 1280\n",
    "WTA = \"top\"\n",
    "SPARSE = True\n",
    "SAMPLES = 12\n",
    "\n",
    "N   = 100\n",
    "DIM = 784\n",
    "D   = None\n",
    "\n",
    "NUM_REPEATS = 10\n",
    "NUM_NNS = max(10,int(0.02*N))        \n",
    "DIST_FN = \"norm2\"\n",
    "\n",
    "\n",
    "def plot(matrix2d):\n",
    "    dims = (12, 2)\n",
    "    fig, ax = plt.subplots(figsize=dims, dpi=200)\n",
    "    p = sns.heatmap(matrix2d, ax=ax, cmap=\"viridis\", xticklabels=False, yticklabels=False)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def read_generic_data(filename):\n",
    "    \"\"\" Generic reader for: sift, gist, corel, mnist, glove, audio, msong. \"\"\"\n",
    "    filepath = path.abspath(path.join(getcwd(), filename))\n",
    "    \n",
    "    D = np.zeros((N,DIM))\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line_num,line in enumerate(f):\n",
    "            \n",
    "            cols = line.strip().split(\",\")\n",
    "            assert len(cols) == DIM\n",
    "            \n",
    "            D[line_num,:] = [float(s) for s in cols]\n",
    "            #D[line_num,:] = map(float,cols)\n",
    "            #D[line_num,:] *= -1 # to invert distribution?\n",
    "            \n",
    "    assert line_num+1 == N\n",
    "    \n",
    "    return D\n",
    "\n",
    "\n",
    "def standardize_data(D):\n",
    "    \"\"\" Performs several standardizations on the data.\n",
    "            1) Makes sure all values are non-negative.\n",
    "            2) Sets the mean of example to SET_MEAN.\n",
    "            3) Applies normalization if desired.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Add the most negative number per column (ORN) to make all values >= 0.\n",
    "    for col in range(DIM):\n",
    "        #print(abs(min(D[:,col])))\n",
    "        D[:,col] += abs(min(D[:,col]))\n",
    "        \n",
    "    # 2. Set the mean of each row (odor) to be SET_MEAN.\n",
    "    for row in range(N):\n",
    "        # Multiply by: SET_MEAN / current mean. Keeps proportions the same.\n",
    "        D[row,:] = D[row,:] * ((100 / np.mean(D[row,:])))\n",
    "        D[row,:] = [int(s) for s in D[row,:]]\n",
    "        #D[row,:] = map(int,D[row,:])        \n",
    "        \n",
    "        assert abs(np.mean(D[row,:]) - 100) <= 1\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "def create_rand_proj_matrix(sparseBinary=False, samples=6):\n",
    "    \"\"\" Creates a random projection matrix of size NUM_KENYON by NUM_ORNS. \"\"\"\n",
    "\n",
    "    # Create a sparse, binary random projection matrix.\n",
    "    if sparseBinary:\n",
    "\n",
    "        assert samples <= DIM\n",
    "\n",
    "        # Each row (KC) samples from the glomeruli: every row has num_sample\n",
    "        # random 1s, and 0s everywhere else.\n",
    "        M = np.zeros((NUM_KENYON,DIM))\n",
    "        for row in range(NUM_KENYON):\n",
    "\n",
    "            # Sample NUM_SAMPLE random indices, set these to 1.\n",
    "            for idx in random.sample(range(DIM),samples):\n",
    "                M[row,idx] = 1\n",
    "\n",
    "            # Make sure I didn't screw anything up!\n",
    "            assert sum(M[row,:]) == samples       \n",
    "\n",
    "    # Create a dense, Gaussian random projection matrix.\n",
    "    else:\n",
    "        M = np.random.randn(NUM_KENYON, DIM)\n",
    "\n",
    "    return M\n",
    "\n",
    "\n",
    "def winnerTakeAll():\n",
    "    # Apply WTA to KCs: firing rates at indices corresponding to top/bot/rand/all KCs; 0s elsewhere.\n",
    "    if WTA == \"random\":# fix indices for all odors, otherwise, can't compare.\n",
    "        rand_indices = random.sample(range(NUM_KENYON),HASH_LENGTH)\n",
    "\n",
    "    \n",
    "    H = np.zeros((N, NUM_KENYON))\n",
    "    for i in range(N):\n",
    "        # Take all neurons.\n",
    "        if WTA == \"all\":\n",
    "            assert HASH_LENGTH == NUM_KENYON\n",
    "            indices = range(NUM_KENYON)\n",
    "\n",
    "        # Highest firing neurons.\n",
    "        elif WTA == \"top\":      \n",
    "            indices = np.argpartition(K[i,:],-HASH_LENGTH)[-HASH_LENGTH:] \n",
    "\n",
    "        # Lowest firing neurons.\n",
    "        elif WTA == \"bottom\": \n",
    "            indices = np.argpartition(K[i,:],HASH_LENGTH)[:HASH_LENGTH]\n",
    "            plot([indices])\n",
    "            \n",
    "        # Random neurons. \n",
    "        elif WTA == \"random\": \n",
    "            indices = rand_indices#random.sample(xxrange(NUM_KENYON),HASH_LENGTH)\n",
    "\n",
    "        else: assert False\n",
    "            \n",
    "        H[i,:][indices] = K[i,:][indices]\n",
    "        \n",
    "    return H\n",
    "\n",
    "def main():\n",
    "    x_map = [None] * NUM_REPEATS\n",
    "    for ii in range(NUM_REPEATS):\n",
    "        M = create_rand_proj_matrix(SPARSE, SAMPLES)\n",
    "        K = np.dot(D,np.transpose(M)) \n",
    "        offset,width = 0,10\n",
    "        K = np.floor((K+offset)/width)\n",
    "        H = winnerTakeAll()\n",
    "        x_map[ii] = test_map_dist(D,H)\n",
    "\n",
    "    return [np.mean(x_map), np.std(x_map)]\n",
    "\n",
    "def test_map_dist(D,H):\n",
    "    \"\"\" Computes mean average precision (MAP) and distortion between true nearest-neighbors  \n",
    "        in input space and approximate nearest-neighbors in hash space. \n",
    "    \"\"\"    \n",
    "    queries = random.sample(range(N),100)\n",
    "\n",
    "    MAP = [] # [list of MAP values for each query]      \n",
    "    for i in queries: \n",
    "        temp_i = [] # list of (dist input space,odor) from i.\n",
    "        temp_h = [] # list of (dist hash space ,odor) from i.\n",
    "        for j in range(N):\n",
    "            if i == j: continue\n",
    "\n",
    "            # Distance between i and j in input space.\n",
    "            dij_orig = dist(D[i,:],D[j,:])\n",
    "            if dij_orig <= 0: continue # i and j are duplicates, e.g. corel: i=1022,j=2435.\n",
    "            temp_i.append( (dij_orig,j) )\n",
    "                            \n",
    "            # Distance between i and j in hash space.\n",
    "            dij_hash = dist(H[i,:],H[j,:])\n",
    "            temp_h.append( (dij_hash,j) )\n",
    "                            \n",
    "        assert len(temp_i) == len(temp_h) # == N-1 # not the last part bc of duplicates.\n",
    "\n",
    "        # Create a set of the true NUM_NNS nearest neighbors.\n",
    "        # true_nns = sorted(temp_i)[0:NUM_NNS]      # true NUM_NNS tuples.\n",
    "        true_nns = heapq.nsmallest(NUM_NNS,temp_i) # true NUM_NNS tuples. (faster than above)\n",
    "        true_nns = set([vals[1] for vals in true_nns]) # true NUM_NNS examples.\n",
    "\n",
    "        # Go through predicted nearest neighbors and compute the MAP.\n",
    "        # pred_nns = sorted(temp_h)[0:NUM_NNS]      # pred NUM_NNS tuples.\n",
    "        pred_nns = heapq.nsmallest(NUM_NNS,temp_h) # pred NUM_NNS tuples. (faster than above)\n",
    "        pred_nns = [vals[1] for vals in pred_nns] # pred NUM_NNS examples.\n",
    "\n",
    "        assert len(true_nns) == len(pred_nns)\n",
    "\n",
    "        # Compute MAP: https://makarandtapaswi.wordpress.com/2012/07/02/intuition-behind-average-precision-and-map/\n",
    "        # E.g.  if the top NUM_NNS results are:   1, 0, 0,   1,   1,   1\n",
    "        #       then the MAP is:            avg(1/1, 0, 0, 2/4, 3/5, 4/6)\n",
    "        num_correct_thus_far = 0\n",
    "        map_temp = []\n",
    "        for idx,nghbr in enumerate(pred_nns):\n",
    "\n",
    "            if nghbr in true_nns:\n",
    "                num_correct_thus_far += 1\n",
    "            \n",
    "            map_temp.append((num_correct_thus_far)/(idx+1))\n",
    "\n",
    "        map_temp = np.mean(map_temp) if len(map_temp) > 0 else 0\n",
    "        assert 0.0 <= map_temp <= 1.0\n",
    "\n",
    "        MAP.append(map_temp)\n",
    "\n",
    "    # Store overall performance for these queries.\n",
    "    x_map = np.mean(MAP)\n",
    "        \n",
    "    return x_map\n",
    "\n",
    "def dist(X,Y):\n",
    "    \"\"\" Computes the distance between two vectors. \"\"\" \n",
    "\n",
    "    if DIST_FN == \"norm1\":\n",
    "        return np.linalg.norm((X-Y),ord=1)\n",
    "    elif DIST_FN == \"norm2\": \n",
    "        return np.linalg.norm((X-Y),ord=2) # same as scipy euclidean but faster!\n",
    "    else:\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d0e0c6d2c161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_generic_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/mnist/mnist10k.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e28a3073d31f>\u001b[0m in \u001b[0;36mread_generic_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDIM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;31m#D[line_num,:] = map(float,cols)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m#D[line_num,:] *= -1 # to invert distribution?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "D = read_generic_data(\"../data/mnist/mnist100.txt\")\n",
    "plot(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = standardize_data(D)\n",
    "plot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = create_rand_proj_matrix(SPARSE, SAMPLES)\n",
    "plot(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.dot(D,np.transpose(M)) \n",
    "plot(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset,width = 0,10\n",
    "K = np.floor((K+offset)/width)\n",
    "plot(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = winnerTakeAll()\n",
    "plot(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_i = []\n",
    "dij_orig = dist(D[1,:],D[2,:])\n",
    "temp_i.append( (dij_orig,2) )\n",
    "temp_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_map_dist(D,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_map = [None] * NUM_REPEATS\n",
    "start = time.time()\n",
    "\n",
    "for ii in range(NUM_REPEATS):\n",
    "    x_map[ii] = test_map_dist(D,H)\n",
    "\n",
    "[DIM, SPARSE, SAMPLES, NUM_KENYON, WTA, HASH_LENGTH, np.mean(x_map), np.std(x_map), (time.time()-start) / 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
